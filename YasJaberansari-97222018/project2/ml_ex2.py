# -*- coding: utf-8 -*-
"""ML_ex2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gSVeqtoA1P05ZbOdAkpLEr1lWryVSqUa
"""

import pandas as pd
import numpy as np # linear algebra
! pip install -q kaggle
from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d corrieaar/apartment-rental-offers-in-germany
!ls
!unzip '/content/apartment-rental-offers-in-germany.zip' -d '/content/'
df = pd.read_csv('/content/immo_data.csv')

df.head(5)

df.info()

df.describe()

df = df.drop(columns=df.columns[((df.isna().sum()/len(df)) > 0.50)])
df.columns

df[df['livingSpace'] == 0.0].shape[0]

df.shape

df.fillna(df._get_numeric_data().mean(),inplace = True)

df1 = df.select_dtypes(['number']) #drop non numerical columns
df1

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(df1)
scaler.transform(df1)

"""ex1"""

c = df.corr().abs()

s = c.unstack()
so = s.sort_values(kind="quicksort")

print (so.livingSpace)

"""1.1) 5 fold cross validation:


"""

from sklearn.model_selection import KFold

X = df1.livingSpaceRange
y = df1.livingSpace
kf = KFold(n_splits=5)
kf.get_n_splits(X)

print("kf = " ,kf)

for train_index, test_index in kf.split(X): 
  print("TRAIN indices:", train_index)
  print("TEST indices:", test_index)
  X_train, X_test = X[train_index], X[test_index]
  y_train, y_test = y[train_index], y[test_index]
  n = X_train.size
  a = (sum(y_train)*sum((X_train)**2) - sum(X_train)*sum(X_train*y_train))/((n)*(sum((X_train)**2)) - (sum(X_train))**2)
  b = (n*sum(X_train*y_train)- sum(X_train)*sum(y_train))/((n)*(sum((X_train)**2)) - (sum(X_train))**2)
  yprime = a + b*X_test
  MSE = 1/y_test.size *sum((yprime - y_test)**2)
  print("X_test = ")
  print(X_test)
  print("y_test = " )
  print( y_test)
  print("a = " ,a ," b = ", b ," n = ", n)
  print("yprime = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.1) 10 fold cross validation:"""

X = df1.livingSpaceRange
y = df1.livingSpace
kf = KFold(n_splits=10)
kf.get_n_splits(X)

print("kf = " ,kf)

for train_index, test_index in kf.split(X): 
  print("TRAIN indices:", train_index)
  print("TEST indices:", test_index)
  X_train, X_test = X[train_index], X[test_index]
  y_train, y_test = y[train_index], y[test_index]
  n = X_train.size
  a = (sum(y_train)*sum((X_train)**2) - sum(X_train)*sum(X_train*y_train))/((n)*(sum((X_train)**2)) - (sum(X_train))**2)
  b = (n*sum(X_train*y_train)- sum(X_train)*sum(y_train))/((n)*(sum((X_train)**2)) - (sum(X_train))**2)
  yprime = a + b*X_test
  MSE = 1/y_test.size *sum((yprime - y_test)**2)
  print("X_test = ")
  print(X_test)
  print("y_test = " )
  print( y_test)
  print("a = " ,a ," b = ", b ," n = ", n)
  print("yprime = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.2)"""

import numpy as np
import matplotlib.pyplot as plt  # To visualize
import pandas as pd  # To read data
from sklearn.linear_model import LinearRegression

"""1.2) 5 fold"""

data = df1
X = data.iloc[:, 17].values.reshape(-1, 1)  #livingSpaceRange converted into numpy array
Y = data.iloc[:, 9].values.reshape(-1, 1)  #livingSpace converted into numpy array
kf = KFold(n_splits=5)
kf.get_n_splits(X)
print("kf = " ,kf)

for train_index, test_index in kf.split(X): 
  print("TRAIN indices:", train_index)
  print("TEST indices:", test_index)
  X_train, X_test = X[train_index], X[test_index]
  Y_train, Y_test = Y[train_index], Y[test_index]
  linear_regressor = LinearRegression()
  linear_regressor.fit(X_train, Y_train)
  yprime = linear_regressor.predict(X_test)
  MSE = 1/y_test.size *sum((yprime - Y_test)**2)
  print("X_test = ")
  print(X_test)
  print("y_test = " )
  print( y_test)
  print("yprime = ")
  print(yprime)
  print("MSE = " ,MSE)

plt.scatter(X, Y)
plt.plot(X_test, yprime, color='red')
plt.show()

"""1.2) 10 fold"""

data = df1
X = data.iloc[:, 17].values.reshape(-1, 1)  #livingSpaceRange converted into numpy array
Y = data.iloc[:, 9].values.reshape(-1, 1)  #livingSpace converted into numpy array
kf = KFold(n_splits=10)
kf.get_n_splits(X)
print("kf = " ,kf)

for train_index, test_index in kf.split(X): 
  print("TRAIN indices:", train_index)
  print("TEST indices:", test_index)
  X_train, X_test = X[train_index], X[test_index]
  Y_train, Y_test = Y[train_index], Y[test_index]
  linear_regressor = LinearRegression()
  linear_regressor.fit(X_train, Y_train)
  yprime = linear_regressor.predict(X_test)
  MSE = 1/y_test.size *sum((yprime - Y_test)**2)
  print("X_test = ")
  print(X_test)
  print("actual Y = " )
  print( y_test)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)
  print(linear_regressor.intercept_)
  print(linear_regressor.coef_)

plt.scatter(X, Y)
plt.plot(X_test, yprime, color='red')
plt.show()

"""1.3)

"""

df3 = df1[['livingSpaceRange' , 'floor' , 'telekomUploadSpeed','noRoomsRange' , 'livingSpace']]
df3
#livingSpaceRange & noRoomsRange are max correlation
#floor and telekomUploadSpeed are min correlation

"""1.3) 10 fold"""

reg = LinearRegression()
kf = KFold(n_splits=10)
kf.get_n_splits(df3)
for train , test in kf.split(df):
  train_data = df3.iloc[train]
  test_data = df3.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.3) 5 fold"""

reg = LinearRegression()
kf = KFold(n_splits=5)
kf.get_n_splits(df3)
for train , test in kf.split(df):
  train_data = df3.iloc[train]
  test_data = df3.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.4)"""

df4 = df1[['yearConstructed' , 'baseRentRange' , 'telekomUploadSpeed','serviceCharge' , 'livingSpace']]
df4

"""1.4) 10 fold"""

reg = LinearRegression()
kf = KFold(n_splits=10)
kf.get_n_splits(df4)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.4) 5 fold"""

reg = LinearRegression()
kf = KFold(n_splits=5)
kf.get_n_splits(df4)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.5)"""

from sklearn.linear_model import Ridge
kf = KFold(n_splits=5)
kf.get_n_splits(df4)
reg = Ridge(alpha=1.0)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  Ridge()
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

from sklearn.linear_model import Ridge
kf = KFold(n_splits=10)
kf.get_n_splits(df4)
reg = Ridge(alpha=1.0)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  Ridge()
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)

"""1.6

"""

from sklearn import linear_model
kf = KFold(n_splits=10)
kf.get_n_splits(df4)
reg = linear_model.Lasso(alpha=0.1)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)
  print(reg.coef_)
  print(reg.intercept_)

from sklearn import linear_model
kf = KFold(n_splits=5)
kf.get_n_splits(df4)
reg = linear_model.Lasso(alpha=0.1)
for train , test in kf.split(df):
  train_data = df4.iloc[train]
  test_data = df4.iloc[test]
  y_trn = train_data['livingSpace']
  x_trn = train_data.drop(columns = ['livingSpace'] )
  y_tst = test_data['livingSpace']
  x_tst = test_data.drop(columns = ['livingSpace'] )
  reg.fit(x_trn , y_trn)
  yprime = reg.predict(x_tst)
  MSE = 1/y_test.size *sum((yprime - y_tst)**2)
  print("X_test = ")
  print(x_tst)
  print("actual Y = " )
  print( y_tst)
  print("predicted = ")
  print(yprime)
  print("MSE = " ,MSE)
  print(reg.coef_)
  print(reg.intercept_)